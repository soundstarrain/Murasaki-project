
<div align="center">
  <img src="https://github.com/soundstarrain/Murasaki-Translator/raw/main/GUI/resources/icon.png" width="160" height="160" style="border-radius: 50%; box-shadow: 0 4px 15px rgba(128, 0, 128, 0.3);">
  
  <h1 style="font-size: 2.5em; margin-bottom: 10px;">ğŸ”® Murasaki Project</h1>
  
  <p align="center">
    <strong>System 2 Reasoning Paradigm for ACGN Translation</strong><br>
    åŸç”Ÿ CoT æ€ç»´é“¾ Â· é•¿ä¸Šä¸‹æ–‡æ”¯æŒ Â· æ²‰æµ¸å¼ç¿»è¯‘ä½“éªŒ
  </p>

  <!-- Badges -->
  <a href="https://huggingface.co/Murasaki-Project" target="_blank">
    <img src="https://img.shields.io/badge/%F0%9F%A4%97%20Hugging%20Face-Murasaki_LLM-ffd21e?style=for-the-badge" alt="Hugging Face">
  </a>
  <a href="https://github.com/soundstarrain/Murasaki-Translator" target="_blank">
    <img src="https://img.shields.io/badge/Tool-Murasaki_GUI-6B21A8?style=for-the-badge&logo=windows" alt="Translator Tool">
  </a>
  <a href="https://github.com/soundstarrain/Murasaki-benchmark" target="_blank">
    <img src="https://img.shields.io/badge/Benchmark-SOTA_Performance-blue?style=for-the-badge&logo=google-analytics" alt="Benchmark">
  </a>

</div>

<br>

## ğŸŒŒ æ„¿æ™¯ (Our Vision)

**Murasaki Project** è‡´åŠ›äºæ¢ç´¢å¤§è¯­è¨€æ¨¡å‹åœ¨ **å‚ç›´é¢†åŸŸæ–‡å­¦ç¿»è¯‘** ä¸­çš„æé™ã€‚

ä¼ ç»Ÿçš„ç›´è§‰å¼ï¼ˆSystem 1ï¼‰æ¨¡å‹å¾€å¾€ä¾èµ–æ¦‚ç‡ç›´è§‰ï¼Œå®¹æ˜“åœ¨è½»å°è¯´å¤æ‚çš„é•¿è·ç¦»ä¼ç¬”ã€ç»†è…»çš„äººç‰©è¯­æ°”å’Œé¢‘ç¹çš„äººç§°çœç•¥ä¸­å‡ºé”™ã€‚

æˆ‘ä»¬æå‡ºäº† **System 2 Translation Paradigm** â€”â€” é€šè¿‡å¼•å…¥æ˜¾å¼æ€ç»´é“¾ (**Chain-of-Thought**)ï¼Œè®©æ¨¡å‹åƒäººç±»èµ„æ·±è¯‘è€…ä¸€æ ·ï¼š
> **(å…ˆé˜…è¯»è¯­å¢ƒ -> åˆ†ææ–‡é£ä¸é€»è¾‘ -> è½ç¬”ç¿»è¯‘)**

åœ¨ `<think>` æ ‡ç­¾å†…ï¼Œæ¨¡å‹ä¼šè¿›è¡Œé£æ ¼å®šè°ƒã€åŠ¨ä½œæµè§£æåŠäººè®¾æ¨å¯¼ã€‚è¿™ç§æœºåˆ¶ç²¾å‡†è§£å†³äº† ACGN ç¿»è¯‘ä¸­ **"ä¸»è¯­çœç•¥"**ã€**"äººç§°æ··æ·†"** åŠ **"é£æ ¼æ¼‚ç§»"** çš„ä¸‰å¤§éš¾é¢˜ã€‚

---

## ğŸ“¥ æ¨¡å‹çŸ©é˜µ (Model Matrix)

Murasaki v0.2 ç³»åˆ—ç°å·²å…¨é¢å‘å¸ƒï¼Œè¦†ç›– 8B åˆ° 14B å‚æ•°é‡ï¼Œæ”¯æŒå…¨ç²¾åº¦ä¸ GGUF é‡åŒ–ã€‚

| æ¨¡å‹ç‰ˆæœ¬ (Model) | ç±»å‹ | æ˜¾å­˜å‚è€ƒ | é€‚ç”¨åœºæ™¯ | ä¸‹è½½é“¾æ¥ |
| :--- | :--- | :--- | :--- | :--- |
| **Murasaki-14B-v0.2** | **BF16** | 32GB+ | **æ——èˆ°ç‰ˆ**ï¼šæœ€ä½³æ€§èƒ½ï¼Œç§‘ç ”ä¸å¾®è°ƒé¦–é€‰ | [HuggingFace](https://huggingface.co/Murasaki-Project/Murasaki-14B-v0.2) |
| **Murasaki-14B-v0.2-GGUF** | **GGUF** | 12GB+ | **è¿›é˜¶ç‰ˆ**ï¼šæœ¬åœ°å¤§æ˜¾å­˜ç”¨æˆ·æ¨è | [HuggingFace](https://huggingface.co/Murasaki-Project/Murasaki-14B-v0.2-GGUF) |
| **Murasaki-8B-v0.2** | BF16 | 24GB+ | **æ ‡å‡†ç‰ˆ**ï¼šå…¨ç²¾åº¦æƒé‡ï¼Œå‡è¡¡ä¹‹é€‰ | [HuggingFace](https://huggingface.co/Murasaki-Project/Murasaki-8B-v0.2) |
| **Murasaki-8B-v0.2-GGUF** | **GGUF** | 6GB+ | **è½»é‡ç‰ˆ**ï¼šå…¼å®¹æ€§æœ€å¼ºï¼Œé€‚åˆå¤§å¤šæ•°æ˜¾å¡ | [HuggingFace](https://huggingface.co/Murasaki-Project/Murasaki-8B-v0.2-GGUF) |

---

## ğŸ“Š è¯„æµ‹è¡¨ç° (Benchmark)

æˆ‘ä»¬åœ¨ **[Murasaki-ACGN Benchmark](https://github.com/soundstarrain/Murasaki-benchmark)** ä¸Šè¯„ä¼°äº†å°†è¿‘å››åä¸ªä¸»æµæ¨¡å‹ã€‚
**Murasaki-14B-v0.2** åœ¨ç»¼åˆå¾—åˆ†åŠé•¿çŸ­æ–‡æœ¬æµ‹è¯•ä¸­å‡å–å¾—äº†ç¬¬ä¸€åçš„æˆç»©ã€‚

| Rank | Model | **Overall Avg** | Short | Long |
| :--- | :--- | :--- | :--- | :--- |
| ğŸ¥‡ | **Murasaki-14B-v0.2** | **0.8545** | **0.8289** | **0.8801** |
| ğŸ¥ˆ | Murasaki-8B-v0.1 | 0.8523 | 0.8269 | 0.8778 |
| ğŸ¥‰ | **Murasaki-8B-v0.2** | **0.8522** | **0.8271** | **0.8773** |
| 4 | Gemini-3-Flash-Preview | 0.8512 | 0.8262 | 0.8765 |
| 5 | Sakura-Qwen-2.5-14B | 0.8509 | 0.8282 | 0.8735 |

> *æ³¨ï¼šä»¥ä¸Šåˆ†æ•°åŸºäº IQ4_XS (4-bit) é‡åŒ–ç‰ˆæœ¬æµ‹å¾—ï¼Œå…¨ç²¾åº¦ç‰ˆæœ¬è¡¨ç°é¢„æœŸæ›´ä¼˜ã€‚*

---

## ğŸ› ï¸ å¿«é€Ÿå¼€å§‹ (Usage)

### 1. ä½¿ç”¨ GUI å®¢æˆ·ç«¯ (æ¨è)
ä¸ºäº†è·å¾—æœ€ä½³ä½“éªŒï¼ˆå¹¶è‡ªåŠ¨åº”ç”¨é’ˆå¯¹è½»å°è¯´ã€å‰§æœ¬ã€çŸ­å¥ä¼˜åŒ–çš„ä¸‰ç§ Prompt æ¨¡å¼ï¼‰ï¼Œè¯·ä½¿ç”¨æˆ‘ä»¬é…å¥—å¼€å‘çš„å¼€æºå‰ç«¯ï¼š

ğŸ‘‰ **å‰å¾€ä¸‹è½½ï¼š[Murasaki Translator](https://github.com/soundstarrain/Murasaki-Translator)**

### 2. Python æ¨ç† (Transformers)

ä»¥ä¸‹ä»£ç å±•ç¤ºäº†å¦‚ä½•è°ƒç”¨ **v0.2 æ¨¡å‹çš„è½»å°è¯´æ¨¡å¼**ï¼š

```bash
pip install transformers torch accelerate
```

```python
import torch
from transformers import AutoModelForCausalLM, AutoTokenizer

# æ¨èä½¿ç”¨ 14B ç‰ˆæœ¬ä»¥è·å¾—æœ€ä½³æ•ˆæœ
model_id = "Murasaki-Project/Murasaki-14B-v0.2"

tokenizer = AutoTokenizer.from_pretrained(model_id)
model = AutoModelForCausalLM.from_pretrained(
    model_id, 
    torch_dtype=torch.bfloat16, 
    device_map="auto"
)

# v0.2 ä¸“ç”¨ Prompt æ¨¡æ¿ (è½»å°è¯´æ¨¡å¼)
NOVEL_SYSTEM_PROMPT = """ä½ æ˜¯ä¸€ä½ç²¾é€šäºŒæ¬¡å…ƒæ–‡åŒ–çš„èµ„æ·±è½»å°è¯´ç¿»è¯‘å®¶ã€‚
è¯·å°†æ—¥æ–‡æ–‡æœ¬ç¿»è¯‘æˆæµç•…ã€ä¼˜ç¾çš„ä¸­æ–‡ã€‚

**æ ¸å¿ƒè¦æ±‚ï¼š**
1. **æ·±åº¦æ€è€ƒï¼š** åœ¨ç¿»è¯‘å‰ï¼Œå…ˆåœ¨ <think> æ ‡ç­¾ä¸­åˆ†ææ–‡é£ã€è¡¥å…¨ä¸»è¯­å¹¶æ¢³ç†é€»è¾‘ã€‚
2. **ä¿¡è¾¾é›…ï¼š** è¯‘æ–‡éœ€ç¬¦åˆä¸­æ–‡è½»å°è¯´é˜…è¯»ä¹ æƒ¯ï¼Œè¿˜åŸåŸä½œçš„æ²‰æµ¸æ„Ÿä¸æ–‡å­¦æ€§ã€‚

ã€æœ¯è¯­è¡¨ã€‘
{glossary}"""

# å‡†å¤‡æ•°æ®
glossary_text = "ãƒ¬ãƒ¼ãƒ«ã‚¬ãƒ³: è¶…ç”µç£ç‚®\nå¦¹: å¦¹å¦¹"
jp_text = "ã€ŒãŠå…„ã¡ã‚ƒã‚“ã€ç§ã®ãƒ¬ãƒ¼ãƒ«ã‚¬ãƒ³ã‚’è¦‹ã¦ï¼ã€"

# æ„é€ è¾“å…¥
system_content = NOVEL_SYSTEM_PROMPT.format(glossary=glossary_text)
messages = [
    {"role": "system", "content": system_content},
    {"role": "user", "content": f"è¯·ç¿»è¯‘ï¼š\n{jp_text}"}
]

text = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)
inputs = tokenizer([text], return_tensors="pt").to(model.device)

# ç”Ÿæˆ (å»ºè®® max_new_tokens > 2048 ä»¥å®¹çº³æ€è€ƒè¿‡ç¨‹)
generated_ids = model.generate(
    inputs.input_ids,
    max_new_tokens=4096,
    temperature=0.7,
    repetition_penalty=1.05
)

response = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]

# è§£æè¾“å‡º
if "<think>" in response and "</think>" in response:
    parts = response.split("</think>")
    thought = parts[0].replace("<think>", "").strip()
    translation = parts[1].strip()
    print(f"=== ğŸ§  æ€è€ƒè¿‡ç¨‹ ===\n{thought}\n")
    print(f"=== ğŸ“– ç¿»è¯‘ç»“æœ ===\n{translation}")
else:
    print(response)
```

---

## ğŸ—“ï¸ Roadmap

- [x] å‘å¸ƒ v0.1 Alpha (8B)
- [x] å‘å¸ƒ Murasaki GUI å®¢æˆ·ç«¯
- [x] **å‘å¸ƒ v0.2 æ­£å¼ç‰ˆ (8B & 14B)**
    - [x] å¢å¼ºçš„ CoT é€»è¾‘
    - [x] é’ˆå¯¹è½»å°è¯´/å‰§æœ¬/çŸ­å¥çš„å¤šæ¨¡å¼æ”¯æŒ
    - [x] GGUF é‡åŒ–é€‚é…
- [ ] é€‚é… vLLM æ¨ç†æ¡†æ¶ (è¿›è¡Œä¸­)
- [ ] å‘å¸ƒå¾®è°ƒæ•°æ®é›†ä¸è®­ç»ƒè„šæœ¬

---

## âš ï¸ å…è´£å£°æ˜ (Disclaimer)

1.  æœ¬æ¨¡å‹è¾“å‡ºå†…å®¹ç”± AI ç”Ÿæˆï¼Œä¸ä»£è¡¨å¼€å‘è€…ç«‹åœºã€‚
2.  æ¨¡å‹ä¸»è¦ç”¨äºå­¦æœ¯ç ”ç©¶å’Œä¸ªäººå­¦ä¹ ï¼Œä¸¥ç¦ç”¨äºä»»ä½•å•†ä¸šç”¨é€”ã€‚
3.  ä½¿ç”¨æœ¬æ¨¡å‹æ—¶è¯·éµå®ˆå½“åœ°æ³•å¾‹æ³•è§„ã€‚

---

## ğŸ“„ License

*   **Code:** Apache-2.0
*   **Model Weights:** [CC BY-NC-SA 4.0](https://creativecommons.org/licenses/by-nc-sa/4.0/)

